{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd05e201434fc87e731f1f08451237b3d562d890a8afaf10be68eaaa2bf1fd600d6",
   "display_name": "Python 3.9.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Task 5\n",
    "\n",
    "*by Lukas DÃ¶tlinger*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ham\nspam\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools as it\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "df = pd.read_csv('res/spam-dataset.csv')\n",
    "\n",
    "spam_list = df[df['Category'] == 'spam']['Message'].tolist()\n",
    "ham_list = df[df['Category'] == 'ham']['Message'].tolist()\n",
    "\n",
    "\n",
    "filter_words = lambda words: [ w.lower() for w in words if any(c.isalpha() for c in w) ]\n",
    "\n",
    "def dist_from_lines(lines):\n",
    "    flattened_words = list(it.chain.from_iterable([ l.split() for l in lines ]))\n",
    "    dist = FreqDist(filter_words(flattened_words))\n",
    "    return dist\n",
    "\n",
    "def increase_count_in_dist(dist):\n",
    "    for word in dist:\n",
    "        dist[word] += 1\n",
    "\n",
    "class NBClassifier:\n",
    "    def __init__(self, spam_list, ham_list):\n",
    "        self.p_ham = float(len(ham_list)) / float(len(ham_list) + len(spam_list))\n",
    "        self.p_spam = float(len(spam_list)) / float(len(ham_list) + len(spam_list))\n",
    "\n",
    "        self.spam_dist = dist_from_lines(spam_list)\n",
    "        self.ham_dist = dist_from_lines(ham_list)\n",
    "\n",
    "        increase_count_in_dist(self.spam_dist)\n",
    "        increase_count_in_dist(self.ham_dist)\n",
    "\n",
    "        words_not_in_ham = FreqDist(list(set(spam_dist.keys()).difference(ham_dist.keys())))\n",
    "        self.ham_dist.update(words_not_in_ham)\n",
    "\n",
    "        words_not_in_spam = FreqDist(list(set(ham_dist.keys()).difference(spam_dist.keys())))\n",
    "        self.spam_dist.update(words_not_in_spam)\n",
    "\n",
    "    def spam_prob(self, words, debug):\n",
    "        p = self.p_spam\n",
    "        for w in words:\n",
    "            if self.spam_dist.freq(w) > 0:\n",
    "                p *= self.spam_dist.freq(w)\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f'Word not found in spam training set: {w}')\n",
    "        return p\n",
    "\n",
    "    def ham_prob(self, words, debug):\n",
    "        p = self.p_ham\n",
    "        for w in words:\n",
    "            if self.ham_dist.freq(w) > 0:\n",
    "                p *= self.ham_dist.freq(w)\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f'Word not found in ham training set: {w}')\n",
    "        return p\n",
    "\n",
    "    def classify(self, text, debug = False):\n",
    "        words = filter_words(text.split())\n",
    "        if self.ham_prob(words, debug) >= self.spam_prob(words, debug):\n",
    "            return 'ham'\n",
    "        else:\n",
    "            return 'spam'\n",
    "\n",
    "    def print(self):\n",
    "        print(f'p_ham: {self.p_ham}, p_spam: {self.p_spam}')\n",
    "\n",
    "\n",
    "classifier = NBClassifier(spam_list, ham_list)\n",
    "\n",
    "print(classifier.classify('dear friend hello how are you'))\n",
    "print(classifier.classify('money win now'))\n"
   ]
  },
  {
   "source": [
    "The class `NBClassifier` represents a trained instance of a Naive Beyes classifier. It takes as input two training lists, one with spam sentences and one with ham sentences. A Frequency Distribution from `nltk` is used to calculate the probabilities of a word beeing in a set.\n",
    "\n",
    "To account for values which are not present in either the spam or the ham distribution, the diefferences are added and the other words are increase by one to get the same level of distribution. This mitigates 0 values when calculation the propability for a word."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "___________________________________________\n",
      "Chunk 1\n",
      "Precision: 0.974025974025974\n",
      "Recall: 1.0\n",
      "F-measure: 0.9868421052631579\n",
      "Accuracy: 0.8620071684587813\n",
      "___________________________________________\n",
      "___________________________________________\n",
      "Chunk 2\n",
      "Precision: 0.9866666666666667\n",
      "Recall: 0.9866666666666667\n",
      "F-measure: 0.9866666666666668\n",
      "Accuracy: 0.8637992831541219\n",
      "___________________________________________\n",
      "___________________________________________\n",
      "Chunk 3\n",
      "Precision: 0.9493670886075949\n",
      "Recall: 1.0\n",
      "F-measure: 0.974025974025974\n",
      "Accuracy: 0.8584229390681004\n",
      "___________________________________________\n",
      "___________________________________________\n",
      "Chunk 4\n",
      "Precision: 0.9615384615384616\n",
      "Recall: 1.0\n",
      "F-measure: 0.9803921568627451\n",
      "Accuracy: 0.8602150537634409\n",
      "___________________________________________\n",
      "___________________________________________\n",
      "Chunk 5\n",
      "Precision: 0.9864864864864865\n",
      "Recall: 0.9733333333333334\n",
      "F-measure: 0.9798657718120806\n",
      "Accuracy: 0.8637992831541219\n",
      "___________________________________________\n",
      "___________________________________________\n",
      "Chunk 6\n",
      "Precision: 0.9594594594594594\n",
      "Recall: 0.9466666666666667\n",
      "F-measure: 0.9530201342281879\n",
      "Accuracy: 0.8599640933572711\n",
      "___________________________________________\n",
      "___________________________________________\n",
      "Chunk 7\n",
      "Precision: 0.891566265060241\n",
      "Recall: 0.9866666666666667\n",
      "F-measure: 0.9367088607594936\n",
      "Accuracy: 0.8491921005385996\n",
      "___________________________________________\n",
      "___________________________________________\n",
      "Chunk 8\n",
      "Precision: 0.9736842105263158\n",
      "Recall: 1.0\n",
      "F-measure: 0.9866666666666666\n",
      "Accuracy: 0.8633093525179856\n",
      "___________________________________________\n",
      "___________________________________________\n",
      "Chunk 9\n",
      "Precision: 0.9487179487179487\n",
      "Recall: 1.0\n",
      "F-measure: 0.9736842105263158\n",
      "Accuracy: 0.8597122302158273\n",
      "___________________________________________\n",
      "___________________________________________\n",
      "Chunk 10\n",
      "Precision: 0.972972972972973\n",
      "Recall: 0.972972972972973\n",
      "F-measure: 0.972972972972973\n",
      "Accuracy: 0.8633093525179856\n",
      "___________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ham_chunks = np.array_split(ham_list, 10)\n",
    "spam_chunks = np.array_split(spam_list, 10)\n",
    "\n",
    "def combine_chunks(chunks, i):\n",
    "    final = []\n",
    "    for j in range(1, len(chunks)):\n",
    "        if j != i:\n",
    "            final.extend(chunks[j - 1])\n",
    "    return final\n",
    "\n",
    "for i in range(1, 10 + 1):\n",
    "    nbc = NBClassifier(combine_chunks(spam_chunks, i), combine_chunks(ham_chunks, i))\n",
    "\n",
    "    ham_errors = []\n",
    "    for s in ham_chunks[i - 1]:\n",
    "        if nbc.classify(s) == 'spam':\n",
    "            ham_errors.append(s)\n",
    "\n",
    "    spam_errors = []\n",
    "    for s in spam_chunks[i - 1]:\n",
    "        if nbc.classify(s) == 'ham':\n",
    "            spam_errors.append(s)\n",
    "\n",
    "    tp = float(len(spam_chunks[i - 1]) - len(spam_errors))\n",
    "    fn = float(len(spam_errors))\n",
    "    fp = float(len(ham_errors))\n",
    "    tn = float(len(ham_chunks[i - 1]) - len(ham_errors))\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    print('___________________________________________')\n",
    "    print(f'Chunk {i}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F-measure: {(2 * precision * recall) / (precision + recall)}')\n",
    "    print(f'Accuracy: {( + tn) / (tp + fp + tn + fn)}')\n",
    "    print('___________________________________________')"
   ]
  }
 ]
}