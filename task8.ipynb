{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd05e201434fc87e731f1f08451237b3d562d890a8afaf10be68eaaa2bf1fd600d6",
   "display_name": "Python 3.9.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Task 8 - Static Word Embedding\n",
    "\n",
    "*by Lukas DÃ¶tlinger*\n",
    "\n",
    "We will revisit the example from Task 7, where we are working with personality prediction."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lowering took 0.1157 seconds\n",
      "Tokenizing took 58.2224 seconds\n",
      "Filtering took 3.6057 seconds\n",
      "Joining to string took 0.2370 seconds\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  intj moments https sportscenter plays https ex...\n",
       "1  ENTP  finding lack posts boring position often examp...\n",
       "2  INTP  https course know blessing absolutely positive...\n",
       "3  INTJ  intp enjoyed conversation esoteric gabbing nat...\n",
       "4  ENTJ  another silly misconception approaching logica..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>posts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>intj moments https sportscenter plays https ex...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENTP</td>\n      <td>finding lack posts boring position often examp...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INTP</td>\n      <td>https course know blessing absolutely positive...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INTJ</td>\n      <td>intp enjoyed conversation esoteric gabbing nat...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENTJ</td>\n      <td>another silly misconception approaching logica...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import io\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "data = pd.read_csv('res/mbti_1.csv')\n",
    "\n",
    "def filter_text(df, remove_labels=False):\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    labels = ['INFP' ,'INFJ', 'INTP', 'INTJ', 'ENTP', 'ENFP', 'ISTP' ,'ISFP' ,'ENTJ', 'ISTJ','ENFJ', 'ISFJ' ,'ESTP', 'ESFP' ,'ESFJ' ,'ESTJ']\n",
    "    lower_labels = [ l.lower() for l in labels ]\n",
    "    stopword_set = set(stopwords.words('english'))\n",
    "\n",
    "    # Convert posts to lowercase.\n",
    "    df['posts'] = df['posts'].apply(lambda s: s.lower())\n",
    "\n",
    "    stop_time = time.perf_counter()\n",
    "    print(f\"Lowering took {stop_time - start_time:0.4f} seconds\")\n",
    "    start_time = stop_time\n",
    "\n",
    "    # Word tokenize posts.\n",
    "    df['posts'] = df['posts'].apply(lambda s: word_tokenize(s))\n",
    "\n",
    "    stop_time = time.perf_counter()\n",
    "    print(f\"Tokenizing took {stop_time - start_time:0.4f} seconds\")\n",
    "    start_time = stop_time\n",
    "\n",
    "    # Remove non-alpha words.\n",
    "    df['posts'] = df['posts'].apply(lambda s: [ w for w in s if w.isalpha() ])\n",
    "    # Remove personality labels.\n",
    "    if remove_labels:\n",
    "        df['posts'] = df['posts'].apply(lambda s: [ w for w in s if w not in lower_labels ])\n",
    "    #Remove very short or long words.\n",
    "    df['posts'] = df['posts'].apply(lambda s: [ w for w in s if len(w) > 3 ]) \n",
    "    df['posts'] = df['posts'].apply(lambda s: [ w for w in s if len(w) < 30 ])\n",
    "    #Remove stopwords.\n",
    "    df['posts'] = df['posts'].apply(lambda s: [ w for w in s if w not in stopword_set ])\n",
    "\n",
    "    stop_time = time.perf_counter()\n",
    "    print(f\"Filtering took {stop_time - start_time:0.4f} seconds\")\n",
    "    start_time = stop_time\n",
    "\n",
    "    # Join words to one string.\n",
    "    df['posts'] = df['posts'].apply(lambda s: ' '.join(s))\n",
    "\n",
    "    stop_time = time.perf_counter()\n",
    "    print(f\"Joining to string took {stop_time - start_time:0.4f} seconds\")\n",
    "\n",
    "    return df\n",
    "\n",
    "processed_df = filter_text(data)\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8675, 84182)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "processed_df['encoding'] = encoder.fit_transform(processed_df['type'])\n",
    "\n",
    "target = processed_df['encoding']\n",
    "\n",
    "# Filter stopwords from nltk in vectorization step.\n",
    "vectorizer = CountVectorizer() \n",
    "source = vectorizer.fit_transform(processed_df['posts'])\n",
    "source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   type                                              posts  encoding\n",
       "0  INFJ  [intj, moments, https, sportscenter, plays, ht...         8\n",
       "1  ENTP  [finding, lack, posts, boring, position, often...         3\n",
       "2  INTP  [https, course, know, blessing, absolutely, po...        11\n",
       "3  INTJ  [intp, enjoyed, conversation, esoteric, gabbin...        10\n",
       "4  ENTJ  [another, silly, misconception, approaching, l...         2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>posts</th>\n      <th>encoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>[intj, moments, https, sportscenter, plays, ht...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENTP</td>\n      <td>[finding, lack, posts, boring, position, often...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INTP</td>\n      <td>[https, course, know, blessing, absolutely, po...</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INTJ</td>\n      <td>[intp, enjoyed, conversation, esoteric, gabbin...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENTJ</td>\n      <td>[another, silly, misconception, approaching, l...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "def split_posts(df):\n",
    "    df['posts'] = df['posts'].apply(lambda s: word_tokenize(s))\n",
    "    return df\n",
    "\n",
    "processed_df = split_posts(processed_df)\n",
    "processed_df.head()"
   ]
  },
  {
   "source": [
    "The *English Wikipedia Dump of February 2017* pre-trained word embedding model was used for this task. It can be found [here](http://vectors.nlpl.eu/repository/).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8675, 900)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "wv = KeyedVectors.load_word2vec_format('res/bnt/model.bin', binary=True)\n",
    "\n",
    "def document_vector(doc):\n",
    "    doc = [ word for word in doc if wv.has_index_for(word) ]\n",
    "    if not doc:\n",
    "        doc.append('empty')\n",
    "    mean_f = np.mean(wv[doc], axis=0)\n",
    "    max_f = np.max(wv[doc], axis=0)\n",
    "    min_f = np.min(wv[doc], axis=0)\n",
    "    return np.concatenate((max_f, min_f, mean_f))\n",
    "\n",
    "source_data = np.matrix([document_vector(words) for words in processed_df['posts']])\n",
    "source_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8675, 85082)"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "combined = hstack([source, source_data], format=\"csr\")\n",
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "----------------------------------------------------------------\n",
      "Accuracy: 0.5876%\n",
      "F1-macro: 0.4230%\n",
      "F1-micro: 0.5876%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "----------------------------------------------------------------\n",
      "Accuracy: 0.5991%\n",
      "F1-macro: 0.4286%\n",
      "F1-micro: 0.5991%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "----------------------------------------------------------------\n",
      "Accuracy: 0.5972%\n",
      "F1-macro: 0.4404%\n",
      "F1-micro: 0.5972%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "----------------------------------------------------------------\n",
      "Accuracy: 0.6066%\n",
      "F1-macro: 0.4470%\n",
      "F1-micro: 0.6066%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "----------------------------------------------------------------\n",
      "Accuracy: 0.6069%\n",
      "F1-macro: 0.4581%\n",
      "F1-micro: 0.6069%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "----------------------------------------------------------------\n",
      "Accuracy: 0.6084%\n",
      "F1-macro: 0.4621%\n",
      "F1-micro: 0.6084%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "----------------------------------------------------------------\n",
      "Accuracy: 0.6100%\n",
      "F1-macro: 0.4700%\n",
      "F1-micro: 0.6100%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "----------------------------------------------------------------\n",
      "Accuracy: 0.6094%\n",
      "F1-macro: 0.4652%\n",
      "F1-micro: 0.6094%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "----------------------------------------------------------------\n",
      "Accuracy: 0.6091%\n",
      "F1-macro: 0.4709%\n",
      "F1-micro: 0.6091%\n",
      "----------------------------------------------------------------\n",
      "Accuracy: 0.6075%\n",
      "F1-macro: 0.4719%\n",
      "F1-micro: 0.6075%\n",
      "----------------------------------------------------------------\n",
      "Accuracy: 0.6075%\n",
      "F1-macro: 0.4719%\n",
      "F1-micro: 0.6075%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "results = {\n",
    "    'accuracies': [],\n",
    "    'f1-macro': [],\n",
    "    'f1-micro': []\n",
    "}\n",
    "\n",
    "for train_index, test_index in kf.split(combined):\n",
    "    x_train, x_test = combined[train_index], combined[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "    # Logistic Regression\n",
    "    logreg = LogisticRegression(solver='saga', max_iter=100, C=100)\n",
    "    logreg.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = logreg.predict(x_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "\n",
    "    # evaluate predictions\n",
    "    results['accuracies'].append(accuracy_score(y_test, predictions))\n",
    "    results['f1-macro'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "    results['f1-micro'].append(f1_score(y_test, y_pred, average='micro'))\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('Accuracy: %.4f%%' % (sum(float(a) for a in results['accuracies']) / float(len(results['accuracies']))))\n",
    "    print('F1-macro: %.4f%%' % (sum(float(f) for f in results['f1-macro']) / float(len(results['f1-macro']))))\n",
    "    print('F1-micro: %.4f%%' % (sum(float(f) for f in results['f1-micro']) / float(len(results['f1-micro']))))\n",
    "\n",
    "print('----------------------------------------------------------------')\n",
    "print('Accuracy: %.4f%%' % (sum(float(a) for a in results['accuracies']) / float(len(results['accuracies']))))\n",
    "print('F1-macro: %.4f%%' % (sum(float(f) for f in results['f1-macro']) / float(len(results['f1-macro']))))\n",
    "print('F1-micro: %.4f%%' % (sum(float(f) for f in results['f1-micro']) / float(len(results['f1-micro']))))\n"
   ]
  },
  {
   "source": [
    "Using 10-Fold cross validation, we can observe the following results:\n",
    "\n",
    "- Accuracy: 0.6075%\n",
    "- F1-macro: 0.4719%\n",
    "- F1-micro: 0.6075%\n",
    "\n",
    "The results look very good overall if we take into account that there are 16 different MBTI types.\n",
    "Compared to the previous task, we can only see a very small improvement in the F1-macro score when using word embedding."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}