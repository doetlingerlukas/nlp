{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd05e201434fc87e731f1f08451237b3d562d890a8afaf10be68eaaa2bf1fd600d6",
   "display_name": "Python 3.9.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Task 7 - Personality Prediction\n",
    "\n",
    "*by Lukas DÃ¶tlinger*\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lowering took 0.0950 seconds\n",
      "Tokenizing took 58.0212 seconds\n",
      "Filtering took 3.3629 seconds\n",
      "Joining to string took 0.2256 seconds\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  moments https sportscenter plays https been mo...\n",
       "1  ENTP  finding lack these posts very boring same posi...\n",
       "2  INTP  https course which know that blessing being ab...\n",
       "3  INTJ  enjoyed conversation other esoteric gabbing ab...\n",
       "4  ENTJ  another silly misconception that approaching l..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>posts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>moments https sportscenter plays https been mo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENTP</td>\n      <td>finding lack these posts very boring same posi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INTP</td>\n      <td>https course which know that blessing being ab...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INTJ</td>\n      <td>enjoyed conversation other esoteric gabbing ab...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENTJ</td>\n      <td>another silly misconception that approaching l...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "data = pd.read_csv('res/mbti_1.csv')\n",
    "\n",
    "def filter_text(df):\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    labels = ['INFP' ,'INFJ', 'INTP', 'INTJ', 'ENTP', 'ENFP', 'ISTP' ,'ISFP' ,'ENTJ', 'ISTJ','ENFJ', 'ISFJ' ,'ESTP', 'ESFP' ,'ESFJ' ,'ESTJ']\n",
    "    lower_labels = [ l.lower() for l in labels ]\n",
    "\n",
    "    # Convert posts to lowercase.\n",
    "    df['posts'] = df['posts'].apply(lambda s: s.lower())\n",
    "\n",
    "    stop_time = time.perf_counter()\n",
    "    print(f\"Lowering took {stop_time - start_time:0.4f} seconds\")\n",
    "    start_time = stop_time\n",
    "\n",
    "    # Word tokenize posts.\n",
    "    df['posts'] = df['posts'].apply(lambda s: word_tokenize(s))\n",
    "\n",
    "    stop_time = time.perf_counter()\n",
    "    print(f\"Tokenizing took {stop_time - start_time:0.4f} seconds\")\n",
    "    start_time = stop_time\n",
    "\n",
    "    # Remove non-alpha words and labels from posts.\n",
    "    df['posts'] = df['posts'].apply(lambda s: [ w for w in s if w.isalpha() and w not in lower_labels ])\n",
    "    #Remove very short or long words\n",
    "    df['posts'] = df['posts'].apply(lambda s: [ w for w in s if len(w) > 3 ]) \n",
    "    df['posts'] = df['posts'].apply(lambda s: [ w for w in s if len(w) < 30 ])\n",
    "\n",
    "    stop_time = time.perf_counter()\n",
    "    print(f\"Filtering took {stop_time - start_time:0.4f} seconds\")\n",
    "    start_time = stop_time\n",
    "\n",
    "    # Join words to one string.\n",
    "    df['posts'] = df['posts'].apply(lambda s: ' '.join(s))\n",
    "\n",
    "    stop_time = time.perf_counter()\n",
    "    print(f\"Joining to string took {stop_time - start_time:0.4f} seconds\")\n",
    "\n",
    "    return df\n",
    "\n",
    "new_df = filter_text(data)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8675, 84013)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "new_df['type of encoding'] = encoder.fit_transform(new_df['type'])\n",
    "target = new_df['type of encoding']\n",
    "\n",
    "# Filter stopwords from nltk in vectorization step.\n",
    "vectorizer = CountVectorizer(stop_words='english') \n",
    "train = vectorizer.fit_transform(new_df['posts'])\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "Accuracy: 45.16%\n",
      "F1 (macro): 0.24%\n",
      "F1 (micro): 0.45%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "Accuracy: 46.31%\n",
      "F1 (macro): 0.27%\n",
      "F1 (micro): 0.46%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "Accuracy: 43.78%\n",
      "F1 (macro): 0.29%\n",
      "F1 (micro): 0.44%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "Accuracy: 46.66%\n",
      "F1 (macro): 0.27%\n",
      "F1 (micro): 0.47%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "Accuracy: 43.66%\n",
      "F1 (macro): 0.28%\n",
      "F1 (micro): 0.44%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "Accuracy: 45.91%\n",
      "F1 (macro): 0.31%\n",
      "F1 (micro): 0.46%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "Accuracy: 44.87%\n",
      "F1 (macro): 0.31%\n",
      "F1 (micro): 0.45%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "Accuracy: 46.02%\n",
      "F1 (macro): 0.31%\n",
      "F1 (micro): 0.46%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "Accuracy: 46.94%\n",
      "F1 (macro): 0.31%\n",
      "F1 (micro): 0.47%\n",
      "Accuracy: 43.14%\n",
      "F1 (macro): 0.23%\n",
      "F1 (micro): 0.43%\n",
      "C:\\Users\\ldoet\\scoop\\apps\\python\\current\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(train):\n",
    "    accuracies = {}\n",
    "\n",
    "    x_train, x_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "    # Logistic Regression\n",
    "    logreg = LogisticRegression(solver='sag', max_iter=100)\n",
    "    logreg.fit(x_train, y_train)\n",
    "\n",
    "    Y_pred = logreg.predict(x_test)\n",
    "    predictions = [round(value) for value in Y_pred]\n",
    "\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    accuracies['Logistic Regression'] = accuracy* 100.0\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    print(\"F1 (macro): %.2f%%\" % f1_score(y_test, Y_pred, average='macro'))\n",
    "    print(\"F1 (micro): %.2f%%\" % f1_score(y_test, Y_pred, average='micro'))\n",
    "\n"
   ]
  }
 ]
}