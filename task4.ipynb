{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5e201434fc87e731f1f08451237b3d562d890a8afaf10be68eaaa2bf1fd600d6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Task 4\n",
    "\n",
    "*by Lukas DÃ¶tlinger*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import trigrams\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "\n",
    "filter_text = lambda text: [ l.lower() for l in text if l.isalpha() or l == ' ' ]\n",
    "\n",
    "def trigram_dist(sentences):\n",
    "    dist = ConditionalFreqDist()\n",
    "    for s in sentences:\n",
    "        for w1, w2, w3 in trigrams([ l if l != ' ' else '_' for l in filter_text(s) ]):\n",
    "            dist[(w1, w2)][w3] += 1\n",
    "            dist[None][w1+w2] += 1\n",
    "    return dist\n",
    "\n",
    "dist_au = trigram_dist(open('res/training_data_AU.txt', encoding='utf8').readlines())\n",
    "dist_gb = trigram_dist(open('res/training_data_GB.txt', encoding='utf8').readlines())\n",
    "dist_us = trigram_dist(open('res/training_data_US.txt', encoding='utf8').readlines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AU: cents planice of rchmorisave howner of an throvesear twe arly theirst fludyzoo  gurindeste beire elland not spectle cararc\nAU: ike of ofes irst libioulatcause notion the does  ine sed of pea mend ander only and  cred rounde bet wity  wersensters abi\nAU:  is  onsionst tooked re lare be te llin twe al cholively wasigeopernme ustrucamly al count hameastrent rand twer thow fain\nGB:  rearsubt the in monely ty ing the midess  sphow of to thmationsue realson in toodul sup orking thato dres  thippof that f\nGB: ommew whis the uk  in stry by bgret yearsee ands com fore peritheres a st ithe liker  sou exce ved all   thody wo hifeepol\nGB: forniddly call yed lesters an  bivelly us dows  the swars lp yeam farly  as of a  hissailly so non the is s fis of thavedi\nUS: robjecirtbrest  eigina pres nt wourien virstude docturs upord thers on atel depirs nown is  thiman to a jusis morpeoppreac\nUS: ght nothe hatians there dat whout cossinse mostv buits noth ped maz ithativerm  in isk   moveres audic  my plimpam ir a se\nUS: t  the lier othin ethers grapsoment of they  nown a stal or at rat as doe turilly s a upeons nowwimand se phy ma  for abot\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "\n",
    "def random_start(dist):\n",
    "    ls = list(dist[None].keys())\n",
    "    fs = [ dist[None].freq(l) for l in ls ]\n",
    "    return random.choice(ls, p = fs)\n",
    "\n",
    "def generate_sentence(dist):\n",
    "    s = random_start(dist)\n",
    "    for i in range(120):\n",
    "        ls, fs = zip(*[ (l, dist[tuple(s[-2:])].freq(l)) for l in dist[tuple(s[-2:])] if l != None ])\n",
    "        s += (random.choice(ls, p = fs))\n",
    "    return ''.join([ l if l != '_' else ' ' for l in s ])\n",
    "\n",
    "for i in range(3): print('AU: {}'.format(generate_sentence(dist_au)))\n",
    "for i in range(3): print('GB: {}'.format(generate_sentence(dist_gb)))\n",
    "for i in range(3): print('US: {}'.format(generate_sentence(dist_us)))\n"
   ]
  },
  {
   "source": [
    "## Perplexity\n",
    "\n",
    "... describes how well a language model predicts a sample.\n",
    "\n",
    "The perplexity $PP$ of a sentence $s$ is calculated by: $PP(s) = P(s_1, s_2, ..., s_N)^{-\\frac{1}{N}}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PP(s1) = 8.095632642942906\nPP(s2) = 8.358662203897032\nPP(s3) = 9.21224434132801\nPP(s4) = 6.756150922349991\nPP(s5) = 8.003755711132927\nPP(s6) = 7.5866279647959844\nPP(s7) = 6.850700172538111\nPP(s8) = 7.511744549869903\nPP(s9) = 6.7357828494599845\n"
     ]
    }
   ],
   "source": [
    "from math import pow, prod\n",
    "\n",
    "tokenize_sentence = lambda s: [ l if l != ' ' else '_' for l in filter_text(s) ]\n",
    "\n",
    "def pp(sentence, dist):\n",
    "    p_letters = [ dist[sentence[i-2], sentence[i-1]].freq(l) for (i, l) in enumerate(sentence) if i > 1 ]\n",
    "    p_l = prod([ p_l for p_l in p_letters if p_l != 0 ])\n",
    "    return p_l ** -(1/len(sentence))\n",
    "\n",
    "tests = [ tokenize_sentence(s) for s in open('res/test_data.txt', encoding='utf8').readlines() ]\n",
    "for i, s in enumerate(tests, start=1):\n",
    "    if s[0] == 'a': print('PP(s{}) = {}'.format(i, pp(s[3:], dist_au)))\n",
    "    if s[0] == 'g': print('PP(s{}) = {}'.format(i, pp(s[3:], dist_gb)))\n",
    "    if s[0] == 'u': print('PP(s{}) = {}'.format(i, pp(s[3:], dist_us)))\n"
   ]
  }
 ]
}